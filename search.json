[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Design and analysis of experiments (R notes)",
    "section": "",
    "text": "Preface\nThese are coding notes for the course STAT351. If you don’t have a background in R, please use the course material on R from the STAT201 course here.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Rintro.html",
    "href": "Rintro.html",
    "title": "1  R: Introduction",
    "section": "",
    "text": "1.1 Installing R\nGo to the The Comprehensive R Archive Network (CRAN)\nUnder “Download and Install R,” choose “Linux,” “MacOS X” or “Windows.” If you choose Windows, on the next page choose “base,” and on the following page choose “Download R 4.3.1 for Windows” to download the setup program.\nIf you choose MacOS X or Linux you will need to read through the instructions to find the downloads you need for your machine.\nOnce you have downloaded the setup program, execute it and follow the instructions for installing R on your system. If you have an earlier version of R already installed, you may continue to use it, or you can uninstall it and then install the most recent version, which is R 4.3.1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "Rintro.html#installing-r",
    "href": "Rintro.html#installing-r",
    "title": "1  R: Introduction",
    "section": "",
    "text": "CRAN",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "Rintro.html#installing-rstudio",
    "href": "Rintro.html#installing-rstudio",
    "title": "1  R: Introduction",
    "section": "1.2 Installing RStudio",
    "text": "1.2 Installing RStudio\nhttps://rstudio.com/products/rstudio/download/\nChoose your version: RStudio Desktop, Open Source License, Free. It is strongly recommended that you use the latest release of RStudio (v2023.06). After you install RStudio, you can double click on it and open:\n\n\n\nR Studio\n\n\nUsually you will want to import data from a file corresponding to data associated with a homework problem. Such a file will usually end with the extensions *.txt or *.dat. The data files for this course will always be available on the CD that comes with the text and/or on the course web page. A data file will consist of columns of numbers, with nothing separating the columns but “white space.” If each column has a title on top describing what the data in the column represents (e.g., age, weight, income, etc.), we will say that the file has a header.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "Rintro.html#working-directory",
    "href": "Rintro.html#working-directory",
    "title": "1  R: Introduction",
    "section": "1.3 Working directory",
    "text": "1.3 Working directory\nThe easiest way to import the data into R and have it readily available for the current and future sessions is to first save the data file into your working directory. For example mine is C:\\stat350.\nTo set up the working directory, select the project option by choosing File menu, then New Project, and then Create Project from Existing Directory.\nTo start writing a new R script, navigate to the New File option in the File menu, and select Quarto Document. This will create a *.qmd file. You can write both code and formatted-text in this document. When working on assignment / exam problems, you will work on the *.qmd file, render it as HTML and then submit. You can view some examples on how to write R code and text in a *.qmd file and render it as HTML here.\nFor rough work, i.e., work that won’t be graded, you may use the R script option to write code.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "Rintro.html#getting-started-with-code",
    "href": "Rintro.html#getting-started-with-code",
    "title": "1  R: Introduction",
    "section": "1.4 Getting started with code",
    "text": "1.4 Getting started with code\n\n1.4.1 Reading data\nSuppose you want to work with the data from Problem 19 of Chapter 1, which is in a file named CH01PR19.txt which you have saved from the CD or the course web page in the Datasets folder within your R working directory. Assume the file has no header. You will want to create a Table object in R containing this data. First choose an appropriate name for the table. Assume you choose to name it Data. Then, you can execute the following code :\n\nData &lt;- read.table(\"./Datasets/CH01PR19.txt\")\n\nThen there will be a Table object in R named Data containing the data in rows and columns. To view it, you would type\n\nData\n\nHowever, if it is a large file, you might not be able to view the whole table at once. In that case, you may use the head() function, which will display only the first 6 rows of Data:\n\nhead(Data)\n\n     V1 V2\n1 3.897 21\n2 3.885 14\n3 3.778 28\n4 2.540 22\n5 3.028 21\n6 3.865 31\n\n\nNote that, in the absence of a header, the columns will be named V1, V2, etc., and the rows will be numbered.\nNow if the file does have a header (which you may have added yourself), you need to change the above command to:\n\nData &lt;- read.table(\"CH01PR19.txt\", header=TRUE)\n\nIn this case, when you view the file you will see the title for each column at the top of each column instead of V1, V2, etc. R regards these titles as names for the columns, and not as data.\nIf you want to load the data file from some other directory, you need to type the full path name in the read.table() command. For instance,\n\nData &lt;- read.table(file=\"C:/stat350/CH01PR19.txt\", header=FALSE) \n\nYou may read data manually as well. Here both Return and New are vectors.\n\nReturn &lt;- c(74,66,81,52,73,62,52,45,62,46,60,46,38)\nNew &lt;-c(5,6,8,11,12,15,16,17,18,18,19,20,20)\n\n\n\n1.4.2 Renaming columns\nNow suppose the file Data has two columns, and the first column is the GPA, while the second column is ACT score. If you would like to rename the columns in your R data table so that each column has a descriptive title, you could give the R command:\n\nnames(Data) &lt;- c(\"GPA\", \"ACT\")\n\nThen when you view the file the titles of the columns will have the new names you assigned:\n\nhead(Data)\n\n    GPA ACT\n1 3.897  21\n2 3.885  14\n3 3.778  28\n4 2.540  22\n5 3.028  21\n6 3.865  31\n\n\nNote that you can also give the columns these titles in the data file before you load it into R, and then use the header = TRUE setting when loading. Also, to avoid errors, you should never include a space in the title of any column\n\n\n1.4.3 Exporting data\nSuppose you wish to export Data to file Intro.csv in your folder.\n\nwrite.table(Data, \"C:/stat350/Intro.csv\", col.names=TRUE, sep=\",\")\n\nSuppose you wish to export Data to Intro.txt with a tab delimiter:\n\nwrite.table(Data, \"C:/stat350/Intro.txt\", col.names=TRUE, sep=\"\\t\")\n\nYou may export R objects to other file types in a similar manner.\n\n\n1.4.4 R environment\nIf you want to see which R objects are currently in your R environment, you can type:\n\nls()\n\nYou may also see these objects at the top right corner of the R Studio interface.\nIf you no longer need one or more of these objects, you can remove them. For instance, if you are done with Data, you can type:\n\nrm(Data)\n\nThen Data will no longer be in your current R environment. When you quit R, if you wish to keep all the new objects in your current R environment, be sure to answer Yes when asked, Save workspace image?\n\n\n1.4.5 Scatter plots and simple linear regression\nSuppose the data for Problem 19 of Chapter One has been stored in an R object named Data which has two columns, the first column named GPA and the second column named ACT. You want to make a scatterplot in R with ACT scores on the horizontal axis and GPA on the vertical axis. The R command is:\n\nplot(Data$ACT, Data$GPA)\n\n\n\n\n\n\n\n\nNote that the dollar sign is used to reference either column in the table named Data. The first argument to the plot() function is the column corresponding to the variable associated with the horizontal axis, and the second argument is the column corresponding to the variable associated with the vertical axis. Alternately, you could define two new vector variables, X and Y, to hold the data of the individual columns, and use these vectors as the arguments to the plot() function:\n\nX &lt;- Data$ACT\nY &lt;- Data$GPA\nplot(X, Y)\n\nFor now we will stick with the former approach. The resulting plot appears in the R Graphics Device within the R interface. Click on it to view it, save it, print it, etc.\nNote that whenever you make a new plot the old one will disappear (this can be changed; but not easily), so save it if you don’t want to lose it. However, the current scatterplot is inadequate. It has no title, the axis labels aren’t very informative, and the points are open circles rather than dark filled-in circles. To fix this, we can add some additional settings to the plot() command:\n\nplot(Data$ACT, Data$GPA, main=\"Problem 1.19\", xlab=\"ACT Test Score\", ylab=\"Freshman GPA\", pch=19)\n\n\n\n\n\n\n\n\nNow we obtain a much nicer scatterplot.\nWhatever you put in quotes after main = will be the title for the plot. Whatever you put in quotes after xlab = and ylab = will the the labels for the horizontal and vertical axes, respectively. The number after pch = is a code for the symbol to use for the points. You can try other numbers from 1 to 25. You can also use any symbol on your keyboard for the points, including numerals and letters, using quotes. For instance, if you want to use an asterisk for the points, type pch=\"*\".\nYou may want to also add a plot of the estimated regression function to the scatterplot of the data. This assumes you have already obtained the least squares estimates of the regression coefficients (see “Simple Linear Regression in R”).\n\nfit &lt;- lm(Data$GPA ~ Data$ACT)\nfit &lt;- lm(GPA~ACT, data=Data)   # another option\nplot(Data$ACT, Data$GPA, main=\"Problem 1.19\", xlab=\"ACT Test Score\", ylab=\"Freshman GPA\", pch=19)\nabline(fit, col = \"red\", lwd = 2) #lwd is for line-width\n\n\n\n\n\n\n\n\nThe line will appear superimposed over the data. You can also just type the actual values for the estimated intercept and slope if you prefer.\nYou may also use ggplot2 to make plots if you wish. ggplot() has a more intuitive syntax as it is based on the Grammar of Graphics, and also has more comprehensive formatting options.\n\nlibrary(ggplot2)\nggplot(Data, aes(x = ACT, y = GPA))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  labs(\n    title = \"Problem 1.19\"\n  )\n\n$title\n[1] \"Problem 1.19\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nTo save your plot, click anywhere on the plot, then on the menu bar choose File, then Save as. Choose the format in which you want to save the plot, then where you want to save it on your drive.\nCheck the estimates for the intercept and slope:\n\nfit\n\n\nCall:\nlm(formula = GPA ~ ACT, data = Data)\n\nCoefficients:\n(Intercept)          ACT  \n    2.11405      0.03883  \n\n\nCompute fitted values:\n\nfit$fitted.values \n\nCompute residuals:\n\nfit$residuals\n\nCompute the estimate of \\(\\sigma^2\\), that is, the MSE:\n\nn &lt;- dim(Data)[1]\nsum(fit$residuals^2)/(n-2)\n\n[1] 0.3882848",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "Rintro.html#formatting-.qmd-file",
    "href": "Rintro.html#formatting-.qmd-file",
    "title": "1  R: Introduction",
    "section": "1.5 Formatting *.qmd file:",
    "text": "1.5 Formatting *.qmd file:\nBefore Quarto, *.Rmd files were commonly used to render HTML files with R code and formatted-text. This Cheatsheet is for formatting *.Rmd files. However, you may use it to format *.qmd files as well.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "Rintro.html#some-references-about-using-r",
    "href": "Rintro.html#some-references-about-using-r",
    "title": "1  R: Introduction",
    "section": "1.6 Some references about using R:",
    "text": "1.6 Some references about using R:\n\n100 page Introduction to R from the R website http://www.ics.uci.edu/~jutts/st108/R-intro.pdf\nPractical Regression and Anova using R, by Julian Faraway http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf\nR code by Bryan Goodrich for Kutner et al., Applied Linear Statistical Models 5th ed: https://rpubs.com/bryangoodrich",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R: Introduction</span>"
    ]
  },
  {
    "objectID": "t_test_example.html",
    "href": "t_test_example.html",
    "title": "2  Hypothesis testing examples",
    "section": "",
    "text": "2.1 t-test",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis testing examples</span>"
    ]
  },
  {
    "objectID": "t_test_example.html#t-test",
    "href": "t_test_example.html#t-test",
    "title": "2  Hypothesis testing examples",
    "section": "",
    "text": "2.1.1 Question\nCola manufacturers want to test how much the sweetness of a new cola drink is affected by storage. The sweetness loss due to storage was evaluated by 10 professional tasters (by comparing the sweetness before and after storage):\nTaster          Sweetness loss\n\n 1         2.0\n 2         0.4\n 3         0.7  \n 4         2.0  \n 5       −0.4   \n 6         2.2  \n 7       −1.3   \n 8         1.2  \n 9         1.1\n10         2.3\nObviously, we want to test if storage results in a loss of sweetness\nLet \\(\\mu\\) denote the sweetness loss, thus:\nNull hypothesis: \\(H_0: \\mu = 0\\)\nAlternate hypothesis: \\(H_a: \\mu &gt; 0\\)\n\n\n2.1.2 Solution\nSample mean (\\(\\bar{x}\\)):\n\ndata &lt;- c(2, 0.4, 0.7, 2, -0.4, 2.2, -1.3, 1.2, 1.1, 2.3)\n\nxbar &lt;- mean(data)\nxbar\n\n[1] 1.02\n\n\nT-statistic:\n\nt = xbar/(sd(data)/sqrt(10))\nt\n\n[1] 2.696689\n\n\np-value:\n\n1-pt(t, df = 9)\n\n[1] 0.01226316\n\n\nIf the probability of Type I error considered is 5%, then we reject the null hypothesis, and conclude that the sweetness loss is indeed greater than 0.\nIf the probability of Type I error considered is 1%, then we fail to reject the null hypothesis, and conclude that the sweetness loss is indeed 0.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis testing examples</span>"
    ]
  },
  {
    "objectID": "t_test_example.html#two-sample-t-test",
    "href": "t_test_example.html#two-sample-t-test",
    "title": "2  Hypothesis testing examples",
    "section": "2.2 Two-sample t-test",
    "text": "2.2 Two-sample t-test\n\n2.2.1 Question\nIn a study of lettuce growth, ten seedlings were randomly allocated to be grown in either a standard nutrient solution or in a solution containing extra nitrogen. After 22 days, the plants were harvested and weighed. The table below summarizes the results. Can we conclude that extra nitrogen enhances growth?\n\n\n\nNutrient solution\nn\nmean\nSD\n\n\n\n\nStandard\n5\n3.62\n0.54\n\n\nExtra\n5\n4.17\n0.67\n\n\n\n\n\n2.2.2 Solution\nWe will first test the hypothesis if the variance of the responses corresponding to the two treatments are the same or not.\nWe will assume that the response follows the normal distribution.\nLet \\(\\sigma_{standard}^2\\) denote the variance of the observations treated with standard solution, \\(\\sigma_{extra}^2\\) denote the variance of the observations treated with extra nitrogen. Then,\nNull hypothesis: \\(\\sigma_{standard}^2 = \\sigma_{extra}^2\\)\nAlternate hypothesis: \\(\\sigma_{standard}^2 \\ne \\sigma_{extra}^2\\)\n\n# F-statistic:\nF = (0.54/0.67)^2\nF\n\n[1] 0.6495879\n\n\n\n# Critical values based on a significance level of 5%\nleft_tail_critical_value &lt;- qf(0.025, 4, 4)\nleft_tail_critical_value\n\n[1] 0.1041175\n\n\n\nright_tail_critical_value &lt;- qf(0.975, 4, 4)\nright_tail_critical_value\n\n[1] 9.60453\n\n\nAs the \\(F\\)-statistic is between the critical values, we do not reject the null hypothesis.\nThus, we will use the pooled-variance to conduct a 2-sample t-test for equality of means.\nLet \\(\\mu_{standard}\\) denote the mean growth with the standard solution, \\(\\mu_{extra}\\) denote the mean growth with extra nitrogen. Then,\nNull hypothesis: \\(\\mu_{standard} = \\mu_{extra}\\)\nAlternate hypothesis: \\(\\mu_{standard} \\ne \\mu_{extra}\\)\n\n# Pooled variance\nsp2 = (0.54^2 + 0.67^2)/2\n\n# t-statistic\nt &lt;- (3.62 - 4.17)/(sqrt(sp2*2/5))\n\n#p-value\n2*pt(t, 8)\n\n[1] 0.1908168\n\n\nAs the \\(p\\)-value is high, we do not reject the null hypothesis that the extra nitrogen does not enhance growth.\nAlternatively, the Welch’s test for unequal variances can be used without testing for equality of variances in the two samples.\n\nn = 5; s1 = 0.54; s2 = 0.67\nnu = (n-1)*(((s1^2 + s2^2)/n)^2)/(((s1^2)/n)^2+((s2^2)/n)^2)\nt0 &lt;- (3.62 - 4.17)/(sqrt((s1^2+s2^2)/5))\n\n2*pt(t0, 7.654594)\n\n[1] 0.1924672\n\n\nAs the power of Welch’s t-test is similar to that of Student’s t-test, even when the population variances are equal and sample sizes are balanced, Welch’s test can always be used, irrespective of the variances being equal or not.\nHowever, if the variances are unequal, then Student’s t-test must not be used. Type 1 error rate will be higher for a Student’s t-test, particularly if one of the samples has a relatively higher variance, and a smaller sample size as compared to the other sample.\nThe functions t.test() and power.t.test() can be used to conveniently test the hypothesis, estimate confidence intervals, estimate power of the test, or the observations needed for a certain power of the test. Look at the documentation of these function, by executing the code ?t.test() or ?power.t.test() in the R console, to see the parameters you need to specify for using them.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesis testing examples</span>"
    ]
  },
  {
    "objectID": "ANOVA.html",
    "href": "ANOVA.html",
    "title": "3  One way ANOVA",
    "section": "",
    "text": "3.1 ANOVA Table\nLet us consider an example where we have results from an experiment to compare yields (as measured by dried weight of plants) obtained under a control and two different treatment conditions. The dataset is named as PlantGrowth and it can be found in the library car.\n# Loading the dataset\nlibrary(car)\nlibrary(DescTools)\ndata &lt;- PlantGrowth\nLet us print the anova table.\nanova(lm(weight ~ group, data = data))\n\nAnalysis of Variance Table\n\nResponse: weight\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngroup      2  3.7663  1.8832  4.8461 0.01591 *\nResiduals 27 10.4921  0.3886                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nThe null hypothesis that all treatments are the same is rejected at a significance level of 5%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>One way ANOVA</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#confidence-interval",
    "href": "ANOVA.html#confidence-interval",
    "title": "3  One way ANOVA",
    "section": "3.2 Confidence interval",
    "text": "3.2 Confidence interval\nLet us print the Bonferroni’s confidence intervals:\n\naov_object &lt;- aov(lm(weight ~ group, data = data))\nPostHocTest(aov_object, method = \"bonferroni\")\n\n\n  Posthoc multiple comparisons of means : Bonferroni \n    95% family-wise confidence level\n\n$group\n            diff     lwr.ci    upr.ci   pval    \ntrt1-ctrl -0.371 -1.0825786 0.3405786 0.5832    \ntrt2-ctrl  0.494 -0.2175786 1.2055786 0.2630    \ntrt2-trt1  0.865  0.1534214 1.5765786 0.0134 *  \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBased on Bonferroni’s method, we observe that treatment 1 and treatment 2 are significantly different, but there is no difference between other pairs.\nBonferroni’s confidence intervals are overly conservative. Let us find the confidence intervals basead on Tukey’s method:\n\nPostHocTest(aov_object, method = \"hsd\")\n\n\n  Posthoc multiple comparisons of means : Tukey HSD \n    95% family-wise confidence level\n\n$group\n            diff     lwr.ci    upr.ci   pval    \ntrt1-ctrl -0.371 -1.0622161 0.3202161 0.3909    \ntrt2-ctrl  0.494 -0.1972161 1.1852161 0.1980    \ntrt2-trt1  0.865  0.1737839 1.5562161 0.0120 *  \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>One way ANOVA</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#model-assumptions-check",
    "href": "ANOVA.html#model-assumptions-check",
    "title": "3  One way ANOVA",
    "section": "3.3 Model assumptions check",
    "text": "3.3 Model assumptions check\nThe conclusions of the statistical tests and the confidence intervals are based on the assumption that random error is normally distributed with mean 0 and constant variance, i.e., \\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\).\nThe diagnostic plots and statistical tests for checking model assumptions can be found here.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>One way ANOVA</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#contrasts",
    "href": "ANOVA.html#contrasts",
    "title": "3  One way ANOVA",
    "section": "3.4 Contrasts",
    "text": "3.4 Contrasts\n\n3.4.1 Class comparison\nThis is an example to use orthogonal contrasts to answer questions of interest. The data rice_seed_data.csv consists of the shoot dry weight (in mg) of an experiment to determine the effect of seed treatment by acids on the early growth of rice seeds.\nThe investigator had several specific questions in mind from the beginning: -Do acid treatments affect seedling growth? - Is the effect of organic acids different from that of inorganic acids? - Is there a difference in the effects of the two different organic acids?\nWe will create orthogonal contrasts, and perform an ANOVA analysis to answer these questions.\n\nrice_data &lt;- read.csv('rice_seed_data.csv')\nanova(lm(growth~treatment, data = rice_data))\n\nAnalysis of Variance Table\n\nResponse: growth\n          Df  Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreatment  3 0.87369 0.291232  33.874 3.669e-07 ***\nResiduals 16 0.13756 0.008597                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nc1 &lt;- c(3, -1, -1, -1)\nc2 &lt;- c(0, -2, 1, 1)\nc3 &lt;- c(0, 0, 1, -1)\n\n# Contrast matrix\nmat.contrast &lt;- cbind(c1, c2, c3)\ncolnames(mat.contrast) &lt;- paste0(\"c\",1:3)\n\n# Converting treatment to a factor variable\nrice_data$treatment &lt;- as.factor(rice_data$treatment)\ncontrasts(rice_data$treatment) &lt;- mat.contrast\n\n# ANOVA table\nmodel &lt;- aov(growth ~ treatment, data = rice_data,\n                   contrasts = list(treatment = mat.contrast))\n\n# Splitting the Treatment sum of squares into independent \n# orthogonal contrast components\nsummary.aov(model,split = list(treatment = list(\"Control vs acid\"=1,  \n                              \"Inorganic vs organic\" = 2, 'Between organic'=3)))\n\n                                  Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntreatment                          3 0.8737  0.2912  33.874 3.67e-07 ***\n  treatment: Control vs acid       1 0.7415  0.7415  86.244 7.61e-08 ***\n  treatment: Inorganic vs organic  1 0.1129  0.1129  13.126  0.00229 ** \n  treatment: Between organic       1 0.0194  0.0194   2.252  0.15293    \nResiduals                         16 0.1376  0.0086                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that there is no statistically significant difference between the effect of organic acids. However, there is a statistically significant difference between the effect of inorganic and organic acids, and an even higher statistically significant difference between the weight of seeds in the control group and the weight seeds treated with acid.\n\n\n3.4.2 Trend comparison\nThis is an example to identify if there is a linear, quadratic, or higher order relationship between a continuous treatment and the response.\nConsider the data laser_power.csv, which consists of laser power, and the corresponding strength of the material obtained using a machining process involving the laser. The question to be answered is if there is a linear or quadratic relationship between the laser power and strength of the material.\n\ndata &lt;- read.csv('laser_power.csv')\ndata$power &lt;- as.factor(data$power)\n\n# Linear contrast\nc1 &lt;- c(-1, 0, 1)\n\n# Quadratic contrast\nc2 &lt;- c(1, -2, 1)\n\nmat.contrast &lt;- cbind(c1, c2)\nmodel &lt;- aov(strength ~ power, data = data,\n             contrasts = list(power = mat.contrast))\nsummary.aov(model, split = list(power = list(\"linear\" = 1,\n                                                 \"quadratic\" = 2)))\n\n                   Df Sum Sq Mean Sq F value  Pr(&gt;F)   \npower               2 224.18  112.09  11.318 0.00920 **\n  power: linear     1 223.75  223.75  22.593 0.00315 **\n  power: quadratic  1   0.44    0.44   0.044 0.84083   \nResiduals           6  59.42    9.90                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that there is a linear relationship between laser power and strength. This can be seen visually as well as below.\n\ndata$power &lt;- as.integer(substr(data$power,5,8))\nplot(data$power, data$strength)\nabline(lm(strength~power, data = data))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>One way ANOVA</span>"
    ]
  },
  {
    "objectID": "Multiple_factors.html",
    "href": "Multiple_factors.html",
    "title": "4  Multiple factors",
    "section": "",
    "text": "4.1 Randomized complete block design (RCBD)\nLet us consider an example, where the shear strength of steel plate girders needs to be modeled as a function of the four methods (treatment) and nine girders (blocks).\nlibrary(ACSWR)\nlibrary(reshape2)\nlibrary(DescTools)\nlibrary(lmtest)\n\n# Visualizing treatment effects\ndata(\"girder\")\nboxplot(girder[,2:5])\n\n\n\n\n\n\n\n# Melting data to make it suitable to fit a linear regression model\n# using the 'lm' function\ndata_melt &lt;- melt(girder, variable.name = \"treatment\", id = 'Girder')\nanova(lm(value~Girder+treatment, data = data_melt))\n\nAnalysis of Variance Table\n\nResponse: value\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nGirder     8 0.08949 0.01119  1.6189    0.1717    \ntreatment  3 1.51381 0.50460 73.0267 3.296e-12 ***\nResiduals 24 0.16584 0.00691                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nThe null hypothesis that there is no effect of the method on the sheer strength of the girder is rejected.\nLet us compare the methods pairwise.\naov_object &lt;- aov(value~Girder+treatment, data = data_melt)\n\n# Tukey's method\nPostHocTest(aov_object, method = \"hsd\")$treatment\n\n                        diff       lwr.ci      upr.ci         pval\nKarisruhe-Aarau    0.5452222  0.437124171  0.65332027 3.225975e-12\nLehigh-Aarau       0.2713333  0.163235283  0.37943138 2.106339e-06\nCardiff-Aarau      0.1106667  0.002568616  0.21876472 4.343575e-02\nLehigh-Karisruhe  -0.2738889 -0.381986940 -0.16579084 1.808447e-06\nCardiff-Karisruhe -0.4345556 -0.542653606 -0.32645750 3.675706e-10\nCardiff-Lehigh    -0.1606667 -0.268764717 -0.05256862 2.164599e-03\nAll methods are different from each other according to Tukey’s method (at 5% significance level).\n# Bonferroni's method\nPostHocTest(aov_object, method = \"bonferroni\")$treatment\n\n                        diff       lwr.ci      upr.ci         pval\nKarisruhe-Aarau    0.5452222  0.432559601  0.65788484 3.308011e-12\nLehigh-Aarau       0.2713333  0.158670712  0.38399595 2.208198e-06\nCardiff-Aarau      0.1106667 -0.001995955  0.22332929 5.631958e-02\nLehigh-Karisruhe  -0.2738889 -0.386551510 -0.16122627 1.894578e-06\nCardiff-Karisruhe -0.4345556 -0.547218177 -0.32189293 3.770501e-10\nCardiff-Lehigh    -0.1606667 -0.273329288 -0.04800405 2.453939e-03\nAll methods except Aarau and Cardiff are different from each other according to Bonferroni’s method (at 5% significance level).\nLet us verify if the model assumptions are satisfied.\npar(mfrow = c(2,2))\nmodel &lt;- lm(value~Girder+treatment, data = data_melt)\nplot(model)\nshapiro.test(model$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  model$residuals\nW = 0.94966, p-value = 0.102\nThe errors are normally distribued.\nbptest(model)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model\nBP = 22.205, df = 11, p-value = 0.02283\nThe error variance assumption is also satisfied at a 1% significance level. There is no strong deviation from the assumption.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple factors</span>"
    ]
  },
  {
    "objectID": "Multiple_factors.html#two-way-layout-fixed-effects",
    "href": "Multiple_factors.html#two-way-layout-fixed-effects",
    "title": "4  Multiple factors",
    "section": "4.2 Two-way layout: Fixed effects",
    "text": "4.2 Two-way layout: Fixed effects\nA manufacturer was interested in finding differences in torque values of a lock-nut. The two factors effecting the torque are the type of plating, and whether the locknut is threaded into a bolt or a mandrel. We’ll use two-way ANOVA to find if the two factors or their interaction effect the torque.\n\ndata &lt;- read.table('bolt.dat.txt', header = TRUE)\ndata_melt &lt;- melt(data, variable.name = 'plating', value.name = 'torque')\n\nUsing M.B as id variables\n\nhead(data_melt)\n\n  M.B plating torque\n1   M     P.O     10\n2   M     P.O     13\n3   M     P.O     17\n4   M     P.O     16\n5   M     P.O     15\n6   M     P.O     14\n\nanova(lm(torque ~ M.B*plating, data = data_melt))\n\nAnalysis of Variance Table\n\nResponse: torque\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nM.B          1  821.4  821.40 22.4563 1.604e-05 ***\nplating      2 2290.6 1145.32 31.3118 9.363e-10 ***\nM.B:plating  2  665.1  332.55  9.0916 0.0003952 ***\nResiduals   54 1975.2   36.58                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#data['plating_bolt'] = apply(data_melt[,1:2], axis = 1, function(x) paste)\n\nThe two factors and their interaction significantly effects the torque.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple factors</span>"
    ]
  },
  {
    "objectID": "Multiple_factors.html#two-way-layout-random-effects",
    "href": "Multiple_factors.html#two-way-layout-random-effects",
    "title": "4  Multiple factors",
    "section": "4.3 Two-way layout: Random effects",
    "text": "4.3 Two-way layout: Random effects\nTen food items are being tested by 5 judges (operators) for quality. Each judge inspects a food item 3 times, and gives a score. Answer the following questions with appropriate analysis:\n\nIs there a statistically significant variation in the scores given by judges for the same quality of food? If yes, quantify the variation.\nIs the variation in the scores given by judges for the same quality of food dependent on the food item?\nIs there a statistically significant variation in the quality of the food items after removing the variation in scores due to different judges? If yes, quantify the variation.\n\n\ndata &lt;- read.csv('sensory_data.csv', header = TRUE)\nhead(data)\n\n   Item Operator1 Operator2 Operator3 Operator4 Operator5\n1 Item1       4.3       4.9       3.3       5.3       4.4\n2 Item1       4.3       4.5       4.0       5.5       3.3\n3 Item1       4.1       5.3       3.4       5.7       4.7\n4 Item2       6.0       5.3       4.5       5.9       4.7\n5 Item2       4.9       6.3       4.2       5.5       4.9\n6 Item2       6.0       5.9       4.7       6.3       4.6\n\ndata_melt &lt;- melt(data, variable.name = \"Operator\", value.name = 'property')\n\nUsing Item as id variables\n\nhead(data_melt)\n\n   Item  Operator property\n1 Item1 Operator1      4.3\n2 Item1 Operator1      4.3\n3 Item1 Operator1      4.1\n4 Item2 Operator1      6.0\n5 Item2 Operator1      4.9\n6 Item2 Operator1      6.0\n\nanova(lm(property~Item*Operator, data = data_melt))\n\nAnalysis of Variance Table\n\nResponse: property\n               Df Sum Sq Mean Sq  F value    Pr(&gt;F)    \nItem            9 612.40  68.044 199.3084 &lt; 2.2e-16 ***\nOperator        4  25.49   6.372  18.6643 1.739e-11 ***\nItem:Operator  36  12.97   0.360   1.0549     0.406    \nResiduals     100  34.14   0.341                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nYes, there is a statistically significant variation in the scores given by judges for the same quality of food\nThe standard deviation in the scores given by judges for the same quality of food is:\n\nsqrt((6.37 - 0.36)/30)\n\n[1] 0.4475861\n\n\nThe variation in the scores given by judges for the same quality of food does not depend on the food item\nYes, there is a statistically significant variation in the quality of the food items after removing the variation in scores due to different judges.\nThe standard deviation in the scores given food items after removing the variation due to different judges is:\n\nsqrt((68.04 - 0.36)/15)\n\n[1] 2.124147",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple factors</span>"
    ]
  },
  {
    "objectID": "Computer_model.html",
    "href": "Computer_model.html",
    "title": "5  Computer model",
    "section": "",
    "text": "5.1 Polynomial interpolation\nBelow is an example of a \\(7\\)-point polynomial interpolator.\ncurve(1/(1+x^2), from=-4, to=4, ylim=c(-.7,1))\nx=seq(-4,4,length=7)\ny=1/(1+x^2)\nX=as.matrix(cbind(1,x,x^2,x^3,x^4,x^5,x^6))\na=solve(X,y)\nu=seq(-4,4,length=100)\nyhat=u\nfor(i in 1:100)\n  yhat[i]=sum(c(1,u[i],u[i]^2,u[i]^3,u[i]^4,u[i]^5,u[i]^6)*a)\nlines(u,yhat, col=2, lty=2, lwd = 2)\npoints(x,y,col=2)\nNotice that the polynomial interpolation model tends to be unstable near the edges, this is called Runge’s phenomenon.\nThe instability increases as the degree of the polynomial increases. Consider the same example if 9 equally-spaced points are considered, instead of 7.\ncurve(1/(1+x^2), from=-4, to=4, ylim=c(-.7,1))\nx=seq(-4,4,length=9)\ny=1/(1+x^2)\nX=as.matrix(cbind(1,x,x^2,x^3,x^4,x^5,x^6,x^7,x^8))\na=solve(X,y)\nu=seq(-4,4,length=100)\nyhat=u\nfor(i in 1:100)\n  yhat[i]=sum(c(1,u[i],u[i]^2,u[i]^3,u[i]^4,u[i]^5,u[i]^6, u[i]^7,u[i]^8)*a)\nlines(u,yhat, col='blue', lty=3, lwd = 2)\npoints(x,y,col=\"blue\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computer model</span>"
    ]
  },
  {
    "objectID": "Computer_model.html#splines",
    "href": "Computer_model.html#splines",
    "title": "5  Computer model",
    "section": "5.2 Splines",
    "text": "5.2 Splines\nLet us consider splines as the metamodel to replace the same computer model considered above.\n\ncurve(1/(1+x^2), from=-4, to=4, ylim=c(-.7,1))\n\n# Splines with 7 points\n\nx=seq(-4,4,length=7)\ny=1/(1+x^2)\npoints(x,y,col=2)\na=splinefun(x,y,method=\"natural\")\ncurve(a,add=T,col=2, lwd = 2)\n\n# Splines with 9 points\n\nx=seq(-4,4,length=9)\ny=1/(1+x^2)\npoints(x,y, pch=3,col=3)\na=splinefun(x,y,method=\"natural\")\ncurve(a,add=T,col=3, lty=2, lwd = 2)\n\n\n\n\n\n\n\n\nWe observe that splines fit the points smoothly, which is desired. However, splines do not scale up and are difficult to fit in case of higher dimensions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computer model</span>"
    ]
  },
  {
    "objectID": "Computer_model.html#random-functions",
    "href": "Computer_model.html#random-functions",
    "title": "5  Computer model",
    "section": "5.3 Random functions",
    "text": "5.3 Random functions\nWe will now adopt a statistical approach to replace the computer model with a metamodel, where we view the deterministic computer model as a realization from a stochastic process.\nLet us consider quadratic functions as the random functions to develop the metamodel.\n\nx=seq(-1,1,length=10)\nb=rnorm(3)\ny=b[1]+b[2]*x+b[3]*x^2\nplot(x,y,\"l\", ylim=c(-3,3))\nb=rnorm(3)\ny=b[1]+b[2]*x+b[3]*x^2\nlines(x,y,\"l\")\nfor(i in 1:10)\n{b=rnorm(3)\ny=b[1]+b[2]*x+b[3]*x^2\nlines(x,y,\"l\",col=i)}\n\n\n\n\n\n\n\n\nWe want a more flexible random function, so that a flexible computer model could correspond to a realization from that random function.\nSuppose \\(y(x_i) \\sim N(0, \\sigma^2)\\). Let us plot a realization of this model for \\(\\sigma^2 = 1\\).\n\nN=100\nx=seq(-1,1,length=N)\ny=rnorm(N)\nplot(x,y,\"l\", ylim=c(-3,3))\n\n\n\n\n\n\n\n\nAlthough the function does seem to be flexible, it is not smooth. We want to have a smooth function, which is also flexible, as the metamodel.\nThe reason why the above realization of a computer model is not smooth is because the response values are not correlated. For smooth functions, adjacent points \\(y(x)\\) and \\(y(x + \\Delta)\\) should be positively correlated.\nLet us introduce correlation between response values to make the realizations of the computer models more smooth.\nLet us assume that the response values have an underlying multivariate normal distribution, with a covariance matrix that is not the diagonal matrix.\nFor example, consider the covariance matrix \\(R\\). where:\n\\[R = \\exp\\{-\\theta(x_i-x_j)^2\\}_{100 \\times 100}\\] In the above correlation function, we can control the flexibility by changing the value of \\(\\theta\\). The higher the value of \\(\\theta\\), the lesser is the correlation between the response values, for a given distance between inputs, and the higher is the flexibility of the function. Thus, this correlation function can provide the desired level of flexibility while also providing smoothness in the function.\nThen,\n\\[y \\sim N(0, R)\\] Let us visualize 10 realizations from the above random function to see the smoothness.\nIf \\(z \\sim N(0, 1)\\), then $y = R^{(1/2)}z $.\nProof: Given \\(y = R^{1/2}z\\),\n\\(E(y) = R^{1/2}E(z) = 0\\)\n\\(Var(y) = Var(R^{1/2}z)\\)\n\\(\\implies Var(y) = R^{1/2}Var(z)R^{1/2})\\)\n\\(\\implies Var(y) = R^{1/2}IR^{1/2})\\)\n\\(\\implies Var(y) = R\\)\n\nE=as.matrix(dist(x, diag=T, ,upper=T))\n\n# Correlation matrix R\nR=exp(-0.5*E^2)\neig=eigen(R)\nR=eig$vec%*%diag(sqrt(eig$val+10^(-10)))%*%t(eig$vec)\nz=rnorm(N)\ny=R%*%z\nplot(x,y,\"l\", ylim=c(-3,3))\nfor(i in 1:10)\n  lines(x,R%*%rnorm(N),col=i)\n\n\n\n\n\n\n\n\nWe can increase the flexibility by increasing the value of the correlation parameter \\(\\theta\\) to say \\(\\theta = 5\\), as shown below.\n\nE=as.matrix(dist(x, diag=T, ,upper=T))\n\n# Correlation matrix R\nR=exp(-5*E^2)\neig=eigen(R)\nR=eig$vec%*%diag(sqrt(eig$val+10^(-10)))%*%t(eig$vec)\nz=rnorm(N)\ny=R%*%z\nplot(x,y,\"l\", ylim=c(-3,3))\nfor(i in 1:10)\n  lines(x,R%*%rnorm(N),col=i)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Computer model</span>"
    ]
  },
  {
    "objectID": "Assignment A.html",
    "href": "Assignment A.html",
    "title": "Appendix A — Assignment 1",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment A.html#instructions",
    "href": "Assignment A.html#instructions",
    "title": "Appendix A — Assignment 1",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nMake R code chunks to insert code and type your answer outside the code chunks, in the template provided. Ensure that the solution is written neatly enough to understand and grade.\nQuarto-render the file as HTML to submit. For theoretical questions, you can either type the answer within the template and include the solutions in this file, or write the solution on paper, scan and submit separately.\nThe assignment is worth 100 points, and is due on 15th April 2024 at 11:59 pm.\nUse a significance level \\(\\alpha = 5\\%\\) in all hypothesis tests, unless otherwise specified.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (2 pt)\nFinal answers of each question are written clearly (1 pt).\nThe proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (2 pt)\n\n\n10 points will be deducted in case the provided template is not used (for coding / text-answer questions), and/or the template is not rendered using Quarto markdown.\nFor questions involving derivations (Q2, Q3 and Q5 in this assignment), you are allowed to do them on paper, scan and upload separately. However, you are welcome to type the derivations in this template.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment A.html#q1",
    "href": "Assignment A.html#q1",
    "title": "Appendix A — Assignment 1",
    "section": "Q1",
    "text": "Q1\nWCAS (Weinberg College of Arts and Sciences) is considering replacing keyboards used in offices of all its departments with new keyboards of a different brand. Let the current keyboard be denoted as A, and the new one denoted as B, where A and B can be assumed to be the brands of the keyboards. However, before making the purchase, WCAS is conducting an experiment to test if the new keyboard will increase the typing efficiency.\nFor the experiments mentioned in all the questions below, assume that:\n\nThe manuscripts used in the replications of the experiments are not the same, but are of a fixed length and font size.\nThe effect of typist on the typing time can be considered as a random variable with constant variance, and thus can be combined with the random error due to unknown factors. Typists within the same department as as similar as typists across departments.\nThe effect of manuscript on the typing time can be considered as a random variable. However, manuscripts within the same department are similar, while manuscripts across departments are relatively less similar.\nThe typing time is modeled as:\n\n\\(y = \\mu_{keyboard} + \\beta_{script} + \\epsilon\\),\nwhere the effect of the keyboards is fixed, and the effect of the script is a random variable, whose variance will be higher if scripts from across multiple departments are used as compared to the case if scripts from within the same department are used in the experiment. However, a given script will have the same effect on the typing time if used multiple times in an experiment.\n\nQ1(a)\nThe first experiment is conducted as follows.\n16 manuscripts are distributed randomly among 16 different typists - one manuscript to each typist. The manuscripts are chosen randomly from different departments of WCAS. 8 typists are randomly selected to use keyboard A and the rest use keyboard B.\nThe times taken (in minutes) by the typists for the 2 keyboards are:\n\n\n\nKeyboard A\nKeyboard B\n\n\n\n\n8.73\n10.77\n\n\n11.31\n8.33\n\n\n9.15\n11.87\n\n\n13.78\n8.31\n\n\n11.58\n7.28\n\n\n9.14\n4.99\n\n\n11.05\n12.61\n\n\n9.49\n8.81\n\n\n\nIs there evidence to support the claim that the time taken by keyboard B is less than that by keyboard A?\nState the null and alternate hypothesis, compute the test statistic, conduct the test, and state the conclusion.\n(4 points)\n\na &lt;- c(8.73, 11.31,  9.15, 13.78, 11.58, 9.14, 11.05,  9.49)\nb &lt;- c(10.77,  8.33, 11.87,  8.31,  7.28,  4.99, 12.61,  8.81)\n\n\n\nQ1(b)\nThe company that sells keyboards of brand B contested the conclusions made based on the above test, and asked WCAS to conduct another experiment, where the same script is tested on both the keyboards, and the typing times are compared for the same script across keyboards.\nWCAS randomly distributed 8 scripts among 16 typists, where each script was shared by two typists - one of them typed it with keyboard A, and the other one typed the same script with keyboard B.\nThe times taken (in minutes) by the typists for the 2 keyboards are in the table below. Each row of the table shows time taken to type the same script.\n\n\n\nKeyboard A\nKeyboard B\n\n\n\n\n9.13\n7.58\n\n\n10.31\n9.11\n\n\n6.95\n8.02\n\n\n12.77\n12.75\n\n\n10.26\n8.97\n\n\n8.3\n6.65\n\n\n12.07\n10.34\n\n\n12.24\n11.24\n\n\n\nIs there evidence to support the claim that the time taken by keyboard B is less than that by keyboard A?\nState the null and alternate hypothesis, compute the test statistic, conduct the test, and state the conclusion.\n(4 points)\n\na &lt;- c(9.13, 10.31,  6.95, 12.77, 10.26,  8.3, 12.07, 12.24)\nb &lt;- c(7.58,  9.11,  8.02, 12.75,  8.97,  6.65, 10.34, 11.24)\n\n\n\nQ1(c)\nWere the conclusions based on the experiments in 1(a) different from the experiments in 1(b)? If yes, then why? If no, then why not? Explain in terms of design principles.\n(4 points)\n\n\nQ1(d)\nUnconvinced by the results of the tests in 1(a) and 1(b), WCAS asked the Department of Statistics and Data Science (DSDS) to conduct both types of experiments (1(a) & 1(b)) again.\nDSDS conducted experiments similar to the ones conducted in 1(a) and 1(b). However, they distributed the scripts available within their own department to typists. Note that the scripts within the same department will be similar as compared to scripts across departments.\nFor the first experiment, DSDS randomly distributed 16 scripts among 16 typists - one manuscript to each typist. The typists and manuscripts are chosen randomly from within DSDS. 8 typists are randomly selected to use keyboard A and the rest use keyboard B.\nThe times taken (in minutes) by the typists for the 2 keyboards are:\n\n\n\nKeyboard A\nKeyboard B\n\n\n\n\n10.79\n9.20\n\n\n10.05\n6.53\n\n\n11.17\n9.52\n\n\n10.32\n8.50\n\n\n12.08\n9.75\n\n\n8.81\n9.18\n\n\n11.66\n9.92\n\n\n11.93\n9.09\n\n\n\nIs there evidence to support the claim that the time taken by keyboard B is less than that by keyboard A?\nState the null and alternate hypothesis, compute the test statistic, conduct the test, and state the conclusion.\n(4 points)\n\na &lt;- c(10.79, 10.05, 11.17, 10.32, 12.08,  8.81, 11.66, 11.93)\nb &lt;- c(9.20, 6.53, 9.52, 8.50, 9.75, 9.18, 9.92, 9.09)\n\n\n\nQ1(e)\nAre the conclusions based on the experiment conducted by DSDS in 1(d) the same as that of the experiment conducted in 1(a)?\nWhat do you think can be the reason of the conclusions being the same (if they are indeed the same) or different (if they are indeed different)?\n(4 points)\n\n\nQ1(f)\nFor the seconds experiment, DSDS randomly distributed 8 scripts among 16 typists, where each script was shared by two typists - one of them typed it with keyboard A, and the other one typed the same script with keyboard B.\nThe times taken (in minutes) by the typists for the 2 keyboards are in the table below. Each row of the table shows time taken to type the same script.\n\n\n\nKeyboard A\nKeyboard B\n\n\n\n\n10.99\n8.53\n\n\n9.73\n7.06\n\n\n9.38\n8.32\n\n\n9.29\n10.79\n\n\n8.26\n9.61\n\n\n9.11\n11.00\n\n\n9.51\n8.76\n\n\n9.73\n8.88\n\n\n\nIs there evidence to support the claim that the time taken by keyboard B is less than that by keyboard A?\nState the null and alternate hypothesis, compute the test statistic, conduct the test, and state the conclusion.\n(4 points)\n\na &lt;- c(10.99,  9.73,  9.38,  9.29,  8.26,  9.11,  9.51,  9.73)\nb &lt;- c(8.53,  7.06,  8.32, 10.79, 9.61, 11.00,  8.76,  8.88)\n\n\n\nQ1(g)\nAre the conclusions based on the experiment conducted by DSDS in 1(f) the same as that of the experiment conducted in 1(b)?\nWhat do you think can be the reason of the conclusions being the same (if they are indeed the same) or different (if they are indeed different)?\n(4 points)\n\n\nQ1(h)\nIf the true difference between the mean typing time with the 2 keyboards is 60 seconds, compute the power of the test for each of the 4 tests - 1(a), 1(b), 1(d), and 1(f). You can assume the population variances to be the same for the populations considered in each experiment.\n(8 points)\n\n\nQ1(i)\nWhich test among 1(a), 1(b), 1(d), and 1(f) would you recommend in the future for a similar problem? Why?\nIs there any potential disadvantage of the recommended test?\n(4 points)\n\n\nQ1(j)\nDesign an experiment that uses minimum resources (i.e., minimum replicates) to provide a power of at least 95% in detecting a potential difference of 60 seconds in the typing time taken by the keyboards. Mention the design. You may modify any of the designs in 1(a), 1(b), 1(d), or 1(f), or even combine the results of some of the experiments to come up with a more reliable design.\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment A.html#q2",
    "href": "Assignment A.html#q2",
    "title": "Appendix A — Assignment 1",
    "section": "Q2",
    "text": "Q2\nConsider another experiment to compare two keyboards A and B in terms of typing efficiency. In this experiment, six manuscripts 1-6 are given to the same typist.\n\nQ2(a)\nUse a statistical model to quantify the gains (1) using randomization (use the randomized design on slide 15 of the class presentation), and (2) using balanced randomization.\n(4 points)\n\n\nQ2(b)\nSuppose the following sequence is obtained using balanced randomization:\n\nA-B, 2. A-B, 3. A-B, 4. B-A, 5. B-A, 6. B-A.\n\nWould you use it for the study? What aspect of the sequence makes you concerned?\nCan you relate it to the possibility that the learning effect may decay over time? Assuming that is the case, derive an expression for the expected bias in the estimated typing time difference of the two keyboards, if you use this design.\nHow can you modify the design to reduce the expected bias?\n(2 + 2 + 2 = 6 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment A.html#q3",
    "href": "Assignment A.html#q3",
    "title": "Appendix A — Assignment 1",
    "section": "Q3",
    "text": "Q3\nA fertilizer is claimed to change the mean yield of a crop to 3 times the mean yield without the fertilizer minus 5 units, i.e.,\nmean yield with fertilizer = 3 * (mean yield without fertilizer) - 5\nWe need to conduct a hypothesis test to verify this claim.\nAssume that the variances of the yield of the two populations (with & without the fertilizer), \\(\\sigma_{Fertilizer}^2\\) and \\(\\sigma_{NoFertilizer}^2\\) are known.\n\nQ3(a)\nState the null and alternate hypothesis.\n(4 points)\n\n\nQ3(b)\nFormulate the test statistic.\n(4 points)\n\n\nQ3(c)\nDerive an expression for the ratio of the number of observations to be sampled from each of the populations, so as to maximize the power of the test. Assume a fixed budget of a total of \\(N\\) samples (i.e., sum of number of samples from both the populations is \\(N\\)).\n(6 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment A.html#q4",
    "href": "Assignment A.html#q4",
    "title": "Appendix A — Assignment 1",
    "section": "Q4",
    "text": "Q4\nIn the early stages of research and development experimentation which type of error do you think is most important, type I or type II? Justify your answer.\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment A.html#q5",
    "href": "Assignment A.html#q5",
    "title": "Appendix A — Assignment 1",
    "section": "Q5",
    "text": "Q5\nConsider a hardness testing machine that presses a rod with a pointed tip (treatment) into a metal specimen (experimental unit) with a known force.\nBy measuring the depth of the depression caused by the tip, the hardness of the specimen is determined (observed response).\nTwo different tips (Tip 1 & Tip 2) are available for this machine, and although the precision (variability) of the measurements made by the two tips seems to be the same, it is suspected that one tip produces different mean hardness readings than the other.\nSuppose that the observed hardness, \\(y_{ij}\\) in the experiments is modeled as follows:\n\\(y_{ij} = \\mu_i + \\beta_{j} + \\epsilon_{ij}\\),\nwhere,\n\\(y_{ij}\\) is the observed hardness of the \\(j_{th}\\) metal specimen based on the \\(i^{th}\\) tip,\n\\(\\mu_i\\) is the true mean hardness measured by the \\(i^{th}\\) tip,\n\\(\\beta_{j} \\sim N(0, \\sigma_{\\beta}^2)\\) is a random variable, which is the effect of the nature of the metal specimen on its observed hardness (however, the nature of a given metal specimen will have the same effect on the hardness measured by both the tips if tested repeatedly),\n\\(\\epsilon_{ij} \\sim N(0, \\sigma_{n}^2)\\) is the random variable, which is the effect of unknown factors on the observed hardness \\(y_{ij}\\).\n\\(i = 1,2\\) (There are 2 tips),\n\\(j = 1, ..., n\\) (There are \\(n\\) replicates for each tip)\n\nQ5(a)\nSuppose that a randomly selected set of \\(n\\) metal specimens is assigned to tip 1, and another set of randomly selected \\(n\\) metal specimens is assigned to tip 2 (i.e., a total of 2\\(n\\) specimens are used in the experiment), and the appropriate test is used to test the hypothesis if the mean hardness measured by the two tips is the same.\n\nQ5(a)(i)\nDerive an expression for the expected bias of the estimated difference in the mean hardness measured by the 2 tips.\n(4 points)\n\n\nQ5(a)(ii)\nDerive an expression for the expected variance of the estimated difference in the mean hardness measured by the 2 tips.\n(4 points)\n\n\n\nQ5(b)\nSuppose that a randomly selected set of \\(n\\) metal specimens is assigned to both the tips (i.e., a total of \\(n\\) specimens are used in the experiment). For each specimen, hardness is observed at a point in the specimen using tip 1 and at another point within the same specimen using tip 2. The appropriate test is used to test the hypothesis if the mean hardness measured by the two tips is the same.\n\nQ5(b)(i)\nDerive an expression for the expected bias of the estimated difference in the mean hardness measured by the 2 tips.\n(2 points)\n\n\nQ5(b)(ii)\nDerive an expression for the expected variance of the estimated difference in the mean hardness measured by the 2 tips.\n(3 points)\n\n\n\nQ5(c)\nDerive the condition, when the expected precision of the estimated difference in means of the hardness measured by the two tips will be higher in the experimental design of 5(b) as compared to the experimental design in 5(a).\nHint: Derive the expression when the expected square of the width of the confidence interval based on the design in 5(b) is less than the expected square of the width of the confidence interval based on the design in 5(a).\n(8 points)\n\n\nQ5(d)\nHow does the difference in the precision of the estimated difference (in means of the hardness measured by the two tips) by the two experimental designs (5(a) and 5(b)) change as the number of replicates \\(n\\) are increased in each of those designs.\n(2 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Assignment 1</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html",
    "href": "Assignment B_questions.html",
    "title": "Appendix B — Assignment 2",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html#instructions",
    "href": "Assignment B_questions.html#instructions",
    "title": "Appendix B — Assignment 2",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nMake R code chunks to insert code and type your answer outside the code chunks, in the template provided. Ensure that the solution is written neatly enough to understand and grade.\nQuarto-render the file as HTML to submit. For theoretical questions, you can either type the answer within the template and include the solutions in this file, or write the solution on paper, scan and submit separately.\nThe assignment is worth 100 points, and is due on 24th April 2024 at 11:59 pm.\nUse a significance level \\(\\alpha = 5\\%\\) in all hypothesis tests, unless otherwise specified.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (2 pt)\nFinal answers of each question are written clearly (1 pt).\nThe proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (2 pt)\n\n\n10 points will be deducted in case the provided template is not used (for coding / text-answer questions), and/or the template is not rendered using Quarto markdown.\nFor the question involving derivations (Q4 in this assignment), you are allowed to do them on paper, scan and upload separately. However, you are welcome to type the derivation in this template.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html#q1",
    "href": "Assignment B_questions.html#q1",
    "title": "Appendix B — Assignment 2",
    "section": "Q1",
    "text": "Q1\nIn Q1 of assignment 1, suppose three keyboards were being compared, instead of two. Let us say there were keyboards of another brand C. Assume that the number of replicates of keyboard C were the same as that of keyboards A and B in all the experiments. After the experiment is conducted, ANOVA is used to identify a difference between the typing time of all pairs of keyboards. Will it be more likely or less likely to observe a statistically significant difference between keyboard A and keyboard B in each of the experiments - 1(a), 1(b), 1(d), and 1(f)? Justify your answer.\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html#q2",
    "href": "Assignment B_questions.html#q2",
    "title": "Appendix B — Assignment 2",
    "section": "Q2",
    "text": "Q2\n\nQ2(a)\nA developer has 4 different designs of a food-ordering mobile app. They tested each design 3 times (the design was launched for a week to be tested each time), and recorded the average time spent by a user on the app. The developer is thinking about either using a single best design that stands out, or combine features of designs that bring similar user-engagement. The developer has the following specific questions in mind before the experiment:\n\nIs design B significantly better or worse than the other three designs? Design B will be more expensive to use as the developer will need to purchase some copyrights to use the design for long term. However, design B will be seriously considered if it generates significantly more app time than the other three designs. Otherwise, a combination of the other 3 designs may be considered.\nIs design A significantly better or worse than designs C and D. Design A is targeted towards Gen-Z, while designs C and D are targeted towards millennials. Thus, it will be easier to either combine designs C and D, or just use design A.\nIs design C significantly better or worse than design D? If that is the case, then the developer may not need to combine designs C and D.\n\nConstruct a meaningful set of orthogonal contrasts that will be useful to answer the questions once the experiment has been performed.\n(3 points)\n\n\nQ2(b)\nExperiments were conducted based on the design in the previous question, and the results (average time spent on app per user in minutes) are given below. Conduct statistically independent tests to answer the 3 questions in 2(a).\n\n\n\nApp design A\nApp design B\nApp design C\nApp design D\n\n\n\n\n7.75\n14.69\n9.97\n8.39\n\n\n9.37\n12.16\n10.48\n12.02\n\n\n7.33\n9.86\n10.15\n9.78\n\n\n\n(4 points)\n\ndata &lt;- data.frame(app_time = c(7.75, 9.37, 7.33, 14.69, 12.16,  9.86,  9.97, 10.48, 10.15,  8.39, 12.02, 9.78), design = factor(c(rep(\"A\", 3), rep(\"B\", 3), rep(\"C\", 3), rep(\"D\", 3))))\n\n\n\nQ2(c)\nAnswer each of the questions in 1(a) with a confidence interval, and interpret the interval.\n(6 points)\n\n\nQ2(d)\nTest if the model assumptions are satisfied in the model developed in 2(b).\nRegardless whether the assumptions are satisfied or not, consider the hypothetical scenario that they are not satisfied. Which conclusions will they effect? For each model assumption violation, mention the conclusion effected.\n(6 points)\n\n\nQ2(e)\nConduct an ANOVA analysis to test if the mean user app times of all the designs is the same. Construct confidence intervals of the difference in mean app times of each design using Tukey’s method. Mention the conclusion based on the analysis.\n(4 points)\n\n\nQ2(f)\nDo the conclusions in 2(e) contradict those in 2(b)? If yes, then why? If not, then why not?\n(4 points)\n\n\nQ2(g)\nWhat is the benefit of using orthogonal contrasts, instead of non-orthogonal contrasts? Do orthogonal contrasts reduce the family-wise type I error rate as compared to non-orthogonal contrasts?\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html#q3",
    "href": "Assignment B_questions.html#q3",
    "title": "Appendix B — Assignment 2",
    "section": "Q3",
    "text": "Q3\nExperiments are conducted to compare the average lifetime of batteries of three brands. Five randomly selected batteries of each brand are tested with the following results. The table consists of life of batteries in weeks.\n\n\n\nBrand A\nBrand B\nBrand C\n\n\n\n\n100\n76\n108\n\n\n96\n80\n100\n\n\n92\n75\n96\n\n\n96\n84\n98\n\n\n92\n82\n100\n\n\n\n\nQ3(a)\nWhich brand will you select for use? Justify your answer with statistical analysis.\n(4 points)\n\n\nQ3(b)\nIf the manufacturer will replace without charge any battery that fails in less than 85 weeks, what percentage would the company expect to replace? Consider the brand selected in 3(a).\n(4 points)\n\n\nQ3(c)\nIf we wish to detect a maximum difference in mean battery life of 10 weeks with a probability of at least 0.90, what sample size should be used?\n(4 points)\n\n\nQ3(d)\nIf we wish to construct a 95 percent confidence interval on the difference in two mean battery lives that has an accuracy of \\(\\pm2\\) weeks, how many batteries of each brand must be tested?\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html#q4",
    "href": "Assignment B_questions.html#q4",
    "title": "Appendix B — Assignment 2",
    "section": "Q4",
    "text": "Q4\nSeveral ovens in a metal working shop are used to heat metal specimens. All ovens are supposed to operate at the same temperature, although it is suspected that this may not be true. Three ovens selected at random, and their temperatures on successive heats are noted. The data collected are as follows:\n\n\n\nOven 1\nOven 2\nOven 3\n\n\n\n\n491.5\n488.5\n480.1\n\n\n498.3\n484.65\n484.8\n\n\n498.1\n479.9\n488.25\n\n\n493.5\n477.35\n473\n\n\n493.6\n-\n471.85\n\n\n-\n-\n478.65\n\n\n\n\nQ4(a)\nIs there significant variation in temperature between ovens?\n(2 points)\n\n\nQ4(b)\nDerive the expression for the expected Mean squared treatment \\(E(MS_{Oven})\\) for the model in 4(a). Note that you will need to consider different number of replicates for each oven. Don’t plug-in any values in the expression, leave the expression in an algebraic form.\n(12 points)\n\n\nQ4(c)\nSuppose engineers have modified the oven manufacturing process in the factory to minimize the temperature variation between ovens. The quality testing team has to design an experiment to test the hypothesis test in 4(a) again. They decide to conduct the experiment on a random sample of 3 ovens manufactured based on the new process in the factory.\nAssume that the budget for the total number of replicates (successive heat measurements on all ovens) in the experiment is fixed as \\(N\\). Derive the optimal number of replicates for each oven to maximize the power of the test.\nYou may use the following result.\nThe solution of the problem,\n\\(\\min \\sum_{i=1}^n x_i^2\\), subject to \\(\\sum_{i=1}^n x_i = C\\), where \\(C\\) is a constant, is:\n\\(x_i = C/n\\)\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment B_questions.html#q5",
    "href": "Assignment B_questions.html#q5",
    "title": "Appendix B — Assignment 2",
    "section": "Q5",
    "text": "Q5\nSuppose that experiments are being conducted to analyse the effect of whey protein and creatine (supplement) on growth in muscle mass. The table below show the muscle mass growth (in grams/100 kg body weight) of a randomly selected sample of 32 individuals in a month. Each individual took a different amount of protein (0.4, 0.6, 0.8, or 1.0 grams/kg body weight) and either took the supplement or didn’t take it.\n\n\n\nSupplement\nProtein amount\n\n\n\n\n\n\n\n\n0.4g\n0.6g\n0.8g\n1.0g\n\n\nCreatine\n105.7\n419.2\n608.4\n623.1\n\n\nCreatine\n111.6\n418.4\n602.9\n602.9\n\n\nCreatine\n90.8\n435.3\n591.2\n581.5\n\n\nCreatine\n92.6\n424.2\n589.4\n594.4\n\n\nNone\n104.9\n452.1\n416.0\n366.8\n\n\nNone\n93.5\n447.3\n400.6\n383.3\n\n\nNone\n103.2\n466.4\n407.7\n369.1\n\n\nNone\n109.0\n449.6\n405.9\n370.1\n\n\n\n\nQ5(a)\nAnswer the following questions using orthogonal contrasts:\n\nIs there a linear response of muscle growth to increasing whey protein?\nIs there a quadratic response of muscle growth to increasing whey protein?\nIs there a cubic response of muscle growth to increasing whey protein?\nDoes adding the creatine supplement have a significant effect on increase in muscle growth?\nIs the linear response to muscle growth different in the presence or absence of the creatine supplement?\nIs the quadratic response to muscle growth different in the presence or absence of the creatine supplement?\nIs the cubic response to muscle growth different in the presence or absence of the creatine supplement?\n\n(14 points)\n\n\nQ5(b)\nDemonstrate that the contrasts are orthogonal.\n(4 points)\n\n\nQ5(c)\nCreate a line plot that shows the average effect on muscle growth with increasing whey protein, both with and without supplement (i.e., 2 line plots - one for supplement, and one for no supplement). Based on the results of the plot which whey-protein-supplement combination will be the best for high muscle growth?\n(4 points)\n\n\nQ5(d)\nNow take the uncertainty of the estimates in the plot in 5(c) into account. Will your answer to the recommendation asked in 5(c) change? Why or why not?\nNote: If there are multiple combinations with no statistically significant difference in the muscle growth, and provide statistically significantly higher muscle growth than the rest of the combinations, then recommend the combination with the lower whey protein / supplement, as it will be cheaper.\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Assignment 2</span>"
    ]
  },
  {
    "objectID": "Assignment 3_questions.html",
    "href": "Assignment 3_questions.html",
    "title": "Appendix C — Assignment 3",
    "section": "",
    "text": "Instructions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Assignment 3</span>"
    ]
  },
  {
    "objectID": "Assignment 3_questions.html#instructions",
    "href": "Assignment 3_questions.html#instructions",
    "title": "Appendix C — Assignment 3",
    "section": "",
    "text": "You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nMake R code chunks to insert code and type your answer outside the code chunks, in the template provided. Ensure that the solution is written neatly enough to understand and grade.\nQuarto-render the file as HTML to submit. For theoretical questions, you can either type the answer within the template and include the solutions in this file, or write the solution on paper, scan and submit separately.\nThe assignment is worth 100 points, and is due on 17th May 2024 at 11:59 pm.\nUse a significance level \\(\\alpha = 5\\%\\) in all hypothesis tests, unless otherwise specified.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (2 pt)\nFinal answers of each question are written clearly (1 pt).\nThe proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (2 pt)\n\n\n10 points will be deducted in case the provided template is not used (for coding / text-answer questions), and/or the template is not rendered using Quarto markdown.\nFor questions involving derivations (Q1, Q4(d) in this assignment), you are allowed to do them on paper, scan and upload separately. However, you are welcome to type the derivations in this template.\nTo maintain family-wise error-rate, use Bonferroni’s correction, wherever needed. Do not use Tukey’s correction. This is to ensure consistency and simplicity of solutions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Assignment 3</span>"
    ]
  },
  {
    "objectID": "Assignment 3_questions.html#robustness-to-interaction-effect",
    "href": "Assignment 3_questions.html#robustness-to-interaction-effect",
    "title": "Appendix C — Assignment 3",
    "section": "1 Robustness to interaction effect",
    "text": "1 Robustness to interaction effect\nConsider the randomized complete block design, with no replicates. Suppose that there is a significant interaction between the treatments and the blocks. However, if no interaction is assumed between the treatments and the blocks, will the hypothesis test of testing if all treatments are the same hold?\nAnswer this question by considering 2 different cases:\nCase 1: Fixed treatment effect, fixed block effect\nCase 2: Fixed treatment effect, random block effect\nDerive \\(E(MSTr)\\), and \\(E(MSE)\\) in both the cases to argue whether the hypothesis test is robust to the assumption of no interaction in the respective case.\n(10 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Assignment 3</span>"
    ]
  },
  {
    "objectID": "Assignment 3_questions.html#rcbd-without-replicates",
    "href": "Assignment 3_questions.html#rcbd-without-replicates",
    "title": "Appendix C — Assignment 3",
    "section": "2) RCBD (without replicates)",
    "text": "2) RCBD (without replicates)\nDuring the Covid-19 pandemic, several schools changed their mode of instruction from in-person to virtual or hybrid. As a result, educators decided to test the effect of virtual / hybrid / in-person education on the ACT scores of high school students.\nThe file act_scores1.csv consists of ACT scores of high school students. The average ACT scores are provided for a set of 5 schools randomly selected from all US schools. For each school, the average ACT score is provided for students receiving in-person, virtual, and hybrid education respectively.\nHere the teaching mode (i.e., in-person, virtual, or hybrid) and school are the factors effecting ACT score.\n\n2a) Model\nWrite the model equation with ACT score as the response, and mean ACT score (population mean), teaching mode effects, school effects, and random error, as the independent variables.\n(1 point)\n\n\n2b) Fixed/random effects\nIdentify the teaching mode effect, and school effect as fixed or random. Justify your answer.\n(2 points)\n\n\n2c) School effect\nFind the variance estimate of the school effect.\n(2 points)\n\n\n2d) Teaching mode effect\nFind the variance of the estimate of the difference in any pair of teaching mode effects.\n(2 points)\n\n\n2e) Precision\nUse the result of the previous question to obtain the width of the confidence interval of the difference in the estimates of any pair of teaching mode effects.\n(2 points)\n\n\n2f) Best teaching mode\nWhich teaching mode is the best for students (consider uncertainties)?\n(1 point)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Assignment 3</span>"
    ]
  },
  {
    "objectID": "Assignment 3_questions.html#rcbd-with-replicates",
    "href": "Assignment 3_questions.html#rcbd-with-replicates",
    "title": "Appendix C — Assignment 3",
    "section": "3) RCBD (with replicates)",
    "text": "3) RCBD (with replicates)\nSchools may be interacting with the teaching mode to effect the ACT scores. The file act_scores2.csv consists of replicates of average ACT scores for a given school and teaching mode.\nNote: These average ACT scores may be obtained at different period of times for a given school and teaching mode. However, we are not considering the time period as another potential factor effecting the ACT score for simplicity.\n\n3a) Interaction effect\nShould the interaction effect of teaching mode and school on the average ACT score be considered as fixed or random?\n(1 point)\n\n\n3b) Expectation\nWrite the expression for the expected mean teaching-mode sum-of-squares, the expected mean school sum-of-squares, and the expected interaction sum-of-squares. You do not need to show the derivation.\n(3 points)\n\n\n3c) Teaching mode, and School effect\nIs there a statistically significant variation in school effects? Are all the teaching mode effects the same?\nHint: Conduct appropriate hypothesis tests, you will not get the result directly from the ANOVA table. Find the \\(p\\)-value for each test.\n(4 points)\n\n\n3d) Best teaching mode\nWhich teaching mode is the best for students (consider uncertainties)?\n(2 points)\n\n\n3e) Effects variance\nEstimate the variance of the school effect, and the variance of the interaction effect.\n(4 points)\n\n\n3f) Chance\nWhat is the chance that a school with in-person education has a worse average ACT score than a school with virtual education?\nConsider the degrees of freedom of the \\(t\\)-distribution as the minimum of the degrees of freedom of the terms contributing to the variance estimate in the denominator of the \\(t\\)-statistic.\n(4 points)\n\n\n3g) Teaching mode effect\nFind the variance of the estimate of the difference in any pair of teaching mode effects.\n(2 points)\n\n\n3h) Precision\nUse the result of the previous question to obtain the width of the confidence interval of the difference in the estimates of any pair of teaching mode effects. Did it increase or decrease as compared to that in case of RBCD without replicates [2(e)]? Why?\n(4 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Assignment 3</span>"
    ]
  },
  {
    "objectID": "Assignment 3_questions.html#three-way-anova",
    "href": "Assignment 3_questions.html#three-way-anova",
    "title": "Appendix C — Assignment 3",
    "section": "4) Three-way ANOVA",
    "text": "4) Three-way ANOVA\nBased on exploratory research, it was found that the income status of a student’s family is likely to effect the ACT score, and it may also interact with the teaching mode and school in effecting the ACT score. To analyze these effects, the average ACT score was collected for students of a given income status, school, and being taught with a particular teaching mode.\nThe file act_scores3.csv consists of average ACT score for a given school, teaching mode, and income status of students. There are no replicates, i.e., there is only one observation for a given school, teaching mode, and income status combination.\n\n4a) Model equation\nWrite the model equation.\n(1 point)\n\n\n4b) Two-factor interactions\nGiven that there are no replicates, will be possible to estimate two-factor interactions? Will it be possible to estimate three-factor interactions? Justify your answers.\n(2 + 2 points)\n\n\n4c) Interaction effect\nAmong the three two-factor interaction effects, which interaction effects are fixed, and which are random?\n(3 points)\n\n\n4d) Expectation\nDerive the expressions for the:\n\nExpected mean teaching-mode sum-of-squares [\\(E(MS_{TM})\\)],\nExpected mean school sum-of-squares [\\(E(MS_{School})\\)],\nExpected mean income sum-of-squares [\\(E(MS_{income})\\)],\nExpected mean sum-of-squares of interaction between teaching mode and school [\\(E(MS_{TM-School})\\)],\nExpected mean sum-of-squares of interaction between teaching mode and income status [\\(E(MS_{TM-income})\\)],\nExpected mean sum-of-squares of interaction between school and income status [\\(E(MS_{School-income})\\)]\n\nAs the derivations will be similar, you are allowed to skip steps, and write expressions directly wherever you can.\n(4 points for writing the model equation, and the equations for the relevant means (\\(y_{ijk}, \\bar{y}_{i..}, \\bar{y}_{.j.}, \\bar{y}_{..k}, \\bar{y}_{ij.}, \\bar{y}_{i.k}, \\bar{y}_{.jk}, \\bar{y}_{...}\\)) - a total of 8 equations)\n(1 point for writing the estimates of the main effects)\n(3 points for writing the estimates of the interaction effects)\n(6 \\(\\times\\) 2 = 12 points for taking expectations and writing the derivations)\n\n\n4e) Teaching mode, and School effect\nWhich two-factor interaction effects, and which main-effects are statistically significant?\nHint:\n\nConduct hypothesis tests, you will not get the result directly from the ANOVA table.\nFor testing the statistical significance of school effects, the denominator of the \\(F\\) statistic will be a linear combination of 3 mean sum-of-squares terms. Use the minimum degrees of freedom of the 3 mean sum-of-squares as the degrees of freedom of the denominator.\n\n(6 points)\n\n\n4f) Effects variance\nEstimate the variance of the school effect, and the variance of the relevant interaction effects.\n(3 points)\n\n\n4g) Teaching mode effect\nFind the variance of the estimates of the difference in any pair of teaching mode effects.\n(2 points)\n\n\n4h) Precision\nUse the result of the previous question to obtain the width of the confidence interval of the difference in the estimates of any pair of teaching mode effects.\n(2 points)\n\n\n4i) Change in precision\nHas the width of the confidence interval obtained in the previous question reduced as compared to that in 3(h)? If yes, then why? Given the same number of data points in Qs 3 and 4, why will the width reduce in 4(h) as compared to that in 3(h)?\n(4 points)\n\n\n4j) Best teaching method based on income\nWhich is the best teaching method based on the income status of the student, i.e., which is the best teaching method for:\n\nHigh-income students,\nMedium-income students,\nLow-income students.\n\nInclude uncertainties into account, i.e., there may be multiple best teaching methods for students of a given income status.\n(3 \\(\\times\\) 2 = 6 points)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Assignment 3</span>"
    ]
  },
  {
    "objectID": "Datasets.html",
    "href": "Datasets.html",
    "title": "Appendix D — Assignment templates and Datasets",
    "section": "",
    "text": "Assignment templates and datasets used in the class notes can be found here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assignment templates and Datasets</span>"
    ]
  }
]